{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession.builder.config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\").getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process song-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Process songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "sd_input = config['LOCAL']['SONG_DATA']\n",
    "output_data = config['LOCAL']['OUTPUT_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sd = spark.read.json(sd_input)\n",
    "df_sd.printSchema()\n",
    "df_sd.createOrReplaceTempView(\"song_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs = spark.sql(\"\"\"\n",
    "    SELECT distinct song_id, title, artist_id, year, duration \n",
    "    FROM song_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOGNCJP12A58A80271|Do You Finally Ne...|ARB29H41187B98F0EF|1972|342.56934|\n",
      "|SOOJPRH12A8C141995|   Loaded Like A Gun|ARBGXIG122988F409D|   0|173.19138|\n",
      "|SOFCHDR12AB01866EF|         Living Hell|AREVWGE1187B9B890A|   0|282.43546|\n",
      "|SOWTBJW12AC468AC6E|Broken-Down Merry...|ARQGYP71187FB44566|   0|151.84934|\n",
      "|SOGOSOV12AF72A285E|   ¿Dónde va Chichi?|ARGUVEV1187B98BA17|1997|313.12934|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_path = output_data + 'songs.parquet'\n",
    "songs.write.mode(\"overwrite\").partitionBy(\"year\", \"artist_id\")\\\n",
    "        .parquet(songs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Process artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 898 µs, sys: 141 µs, total: 1.04 ms\n",
      "Wall time: 21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sd.createOrReplaceTempView(\"artist_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 931 µs, sys: 155 µs, total: 1.09 ms\n",
      "Wall time: 23.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atrists = spark.sql(\"\"\"\n",
    "    SELECT distinct artist_id, \n",
    "        artist_name as name,\n",
    "        artist_location as location, \n",
    "        artist_latitude as lattitude,\n",
    "        artist_longitude as longitude\n",
    "    FROM artist_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|artist_id|count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n",
      "CPU times: user 0 ns, sys: 3.62 ms, total: 3.62 ms\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atrists.groupby('artist_id').count().filter('count > 1').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- lattitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atrists.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 ms, sys: 312 µs, total: 2.09 ms\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atrists_path = output_data + 'atrists_table'\n",
    "atrists.write.mode(\"overwrite\").parquet(atrists_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Process song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_song_data(spark, input_data, output_data):\n",
    "    # get filepath to song data file\n",
    "    song_data = input_data\n",
    "    \n",
    "    # read song data file\n",
    "    print('start reading song data')\n",
    "    start = datetime.now()\n",
    "    df = spark.read.json(song_data)\n",
    "    print('finished:', f\"{(datetime.now() - start).total_seconds()} s\")\n",
    "    df.printSchema()\n",
    "    print('------------')\n",
    "\n",
    "    # extract columns to create songs table\n",
    "    \n",
    "    print('start songs columns extractaction')\n",
    "    start = datetime.now()\n",
    "    df.createOrReplaceTempView(\"songs_table\")\n",
    "    songs_table = spark.sql(\"\"\"\n",
    "        SELECT distinct song_id, title, artist_id, year, duration \n",
    "        FROM songs_table\n",
    "    \"\"\")\n",
    "    print('finished:', f\"{(datetime.now() - start).total_seconds()} s\")\n",
    "    songs_table.printSchema()\n",
    "    songs_table.show(5)\n",
    "    print('------------')\n",
    "    \n",
    "    # write songs table to parquet files partitioned by year and artist\n",
    "    print('Start songs table writting')\n",
    "    start = datetime.now()\n",
    "    songs_path = output_data + 'songs_table'\n",
    "    songs_table.write.mode(\"overwrite\").partitionBy(\"year\", \"artist_id\")\\\n",
    "        .parquet(songs_path)\n",
    "    print('finished:', f\"{(datetime.now() - start).total_seconds()} s\")\n",
    "    print('------------')\n",
    "    \n",
    "    # extract columns to create artists table\n",
    "    print('start atrists columns extraction')\n",
    "    start = datetime.now()\n",
    "    df.createOrReplaceTempView(\"artists_table\")\n",
    "    artists_table = spark.sql(\"\"\"\n",
    "        SELECT distinct artist_id, \n",
    "            artist_name as name,\n",
    "            artist_location as location, \n",
    "            artist_latitude as lattitude,\n",
    "            artist_longitude as longitude\n",
    "        FROM artist_data\n",
    "    \"\"\")\n",
    "    print('finished:', f\"{(datetime.now() - start).total_seconds()} s\")\n",
    "    artists_table.printSchema()\n",
    "    artists_table.show(5)\n",
    "    print('------------')\n",
    "    \n",
    "    # write artists table to parquet files\n",
    "    print('Start songs table writting')\n",
    "    start = datetime.now()\n",
    "    atrists_path = output_data + 'atrists_table'\n",
    "    artists_table.write.mode(\"overwrite\").parquet(atrists_path)\n",
    "    print('finished:', f\"{(datetime.now() - start).total_seconds()} s\")\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reading song data\n",
      "finished: 1.374122 s\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "------------\n",
      "start songs columns extractaction\n",
      "finished: 0.02306 s\n",
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      "\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOGNCJP12A58A80271|Do You Finally Ne...|ARB29H41187B98F0EF|1972|342.56934|\n",
      "|SOOJPRH12A8C141995|   Loaded Like A Gun|ARBGXIG122988F409D|   0|173.19138|\n",
      "|SOFCHDR12AB01866EF|         Living Hell|AREVWGE1187B9B890A|   0|282.43546|\n",
      "|SOWTBJW12AC468AC6E|Broken-Down Merry...|ARQGYP71187FB44566|   0|151.84934|\n",
      "|SOGOSOV12AF72A285E|   ¿Dónde va Chichi?|ARGUVEV1187B98BA17|1997|313.12934|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "------------\n",
      "Start songs table writting\n",
      "finished: 5.013049 s\n",
      "------------\n",
      "start atrists columns extraction\n",
      "finished: 0.037438 s\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- lattitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "+------------------+------------+---------------+---------+----------+\n",
      "|         artist_id|        name|       location|lattitude| longitude|\n",
      "+------------------+------------+---------------+---------+----------+\n",
      "|ARPBNLO1187FB3D52F|    Tiny Tim|   New York, NY| 40.71455| -74.00712|\n",
      "|ARBEBBY1187B9B43DB|   Tom Petty|Gainesville, FL|     null|      null|\n",
      "|AR0IAWL1187B9A96D0|Danilo Perez|         Panama|   8.4177| -80.11278|\n",
      "|ARMBR4Y1187B9990EB|David Martin|California - SF| 37.77916|-122.42005|\n",
      "|ARD0S291187B9B7BF5|     Rated R|           Ohio|     null|      null|\n",
      "+------------------+------------+---------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "------------\n",
      "Start songs table writting\n",
      "finished: 3.971366 s\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "input_data = config['LOCAL']['SONG_DATA']\n",
    "output_data = config['LOCAL']['OUTPUT_DATA']\n",
    "process_song_data(spark, input_data, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
